{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Text Language by Counting Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [Detecting Text Language With Python and NLTK by Alejandro Nolla](http://blog.alejandronolla.com/2013/05/15/detecting-text-language-with-python-and-nltk/)\n",
    "\n",
    "*Stop words* are words which are filtered out before processing because they are mostly grammatical as opposed to semantic in nature e.g. search engines remove words like 'want'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T14:04:33.031134Z",
     "start_time": "2019-07-02T14:04:33.026253Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"Yo man, it's time for you to shut yo' mouth! I ain't even messin' dawg.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T14:03:28.537395Z",
     "start_time": "2019-07-02T14:03:27.158821Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "try:\n",
    "    from nltk.tokenize import wordpunct_tokenize # RE-based tokenizer which splits text on whitespace and punctuation (except for underscore)\n",
    "except ImportError:\n",
    "    print('[!] You need to install nltk (http://nltk.org/index.html)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T14:04:34.986667Z",
     "start_time": "2019-07-02T14:04:34.406842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yo',\n",
       " 'man',\n",
       " ',',\n",
       " 'it',\n",
       " \"'\",\n",
       " 's',\n",
       " 'time',\n",
       " 'for',\n",
       " 'you',\n",
       " 'to',\n",
       " 'shut',\n",
       " 'yo',\n",
       " \"'\",\n",
       " 'mouth',\n",
       " '!',\n",
       " 'I',\n",
       " 'ain',\n",
       " \"'\",\n",
       " 't',\n",
       " 'even',\n",
       " 'messin',\n",
       " \"'\",\n",
       " 'dawg',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tokens = wordpunct_tokenize(text)\n",
    "test_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other tokenizers e.g. `RegexpTokenizer` where you can enter your own regexp, `WhitespaceTokenizer` (similar to Python's `string.split()`) and `BlanklineTokenizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring NLTK's stop words corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK comes with a corpus of stop words in various languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T14:05:07.948648Z",
     "start_time": "2019-07-02T14:05:07.930099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stopwords Corpus  This corpus contains lists of stop words for several languages.  These are high-frequency grammatical words which are usually ignored in text retrieval applications.  They were obtained from: http://anoncvs.postgresql.org/cvsweb.cgi/pgsql/src/backend/snowball/stopwords/  The stop words for the Romanian language were obtained from: http://arlc.ro/resources/  The English list has been augmented https://github.com/nltk/nltk_data/issues/22  The German list has been corrected https://github.com/nltk/nltk_data/pull/49  A Kazakh list has been added https://github.com/nltk/nltk_data/pull/52  A Nepali list has been added https://github.com/nltk/nltk_data/pull/83  An Azerbaijani list has been added https://github.com/nltk/nltk_data/pull/100  A Greek list has been added https://github.com/nltk/nltk_data/pull/103  An Indonesian list has been added https://github.com/nltk/nltk_data/pull/112 '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.readme().replace('\\n', ' ') # Since this is raw text, we need to replace \\n's with spaces for it to be readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T14:14:25.787400Z",
     "start_time": "2019-07-02T14:14:25.779588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.fileids() # Most corpora consist of a set of files, each containing a piece of text. A list of identifiers for these files is accessed via fileids()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus readers provide a variety of methods to read data from the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T14:36:12.117113Z",
     "start_time": "2019-07-02T14:36:12.108328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a\\r\\naby\\r\\nach\\r\\nacz\\r\\naczkolwiek\\r\\naj\\r\\nalbo\\r\\nale\\r\\nalez\\r\\należ\\r\\nani\\r\\naz\\r\\naż\\r\\nbardziej\\r\\nbardzo\\r\\nbeda\\r\\nbedzie\\r\\nbez\\r\\ndeda\\r\\nbędš\\r\\nbede\\r\\nbędę\\r\\nbędzie\\r\\nbo\\r\\nbowiem\\r\\nby\\r\\nbyc\\r\\nbyć\\r\\nbyl\\r\\nbyla\\r\\nbyli\\r\\nbylo\\r\\nbyly\\r\\nbył\\r\\nbyła\\r\\nbyło\\r\\nbyły\\r\\nbynajmniej\\r\\ncala\\r\\ncali\\r\\ncaly\\r\\ncała\\r\\ncały\\r\\nci\\r\\ncie\\r\\nciebie\\r\\ncię\\r\\nco\\r\\ncokolwiek\\r\\ncos\\r\\nco\\x9c\\r\\nczasami\\r\\nczasem\\r\\nczemu\\r\\nczy\\r\\nczyli\\r\\ndaleko\\r\\ndla\\r\\ndlaczego\\r\\ndlatego\\r\\ndo\\r\\ndobrze\\r\\ndokad\\r\\ndokšd\\r\\ndosc\\r\\ndo\\x9cć\\r\\nduzo\\r\\ndużo\\r\\ndwa\\r\\ndwaj\\r\\ndwie\\r\\ndwoje\\r\\ndzis\\r\\ndzisiaj\\r\\ndzi\\x9c\\r\\ngdy\\r\\ngdyby\\r\\ngdyz\\r\\ngdyż\\r\\ngdzie\\r\\ngdziekolwiek\\r\\ngdzies\\r\\ngdzie\\x9c\\r\\ngo\\r\\ni\\r\\nich\\r\\nile\\r\\nim\\r\\ninna\\r\\ninne\\r\\ninny\\r\\ninnych\\r\\niz\\r\\niż\\r\\nja\\r\\njak\\r\\njakas\\r\\njaka\\x9c\\r\\njakby\\r\\njaki\\r\\njakichs\\r\\njakich\\x9c\\r\\njakie\\r\\njakis\\r\\njaki\\x9c\\r\\njakiz\\r\\njakiż\\r\\njakkolwiek\\r\\njako\\r\\njakos\\r\\njako\\x9c\\r\\njš\\r\\nje\\r\\njeden\\r\\njedna\\r\\njednak\\r\\njednakze\\r\\njednakże\\r\\njedno\\r\\njego\\r\\njej\\r\\njemu\\r\\njesli\\r\\njest\\r\\njestem\\r\\njeszcze\\r\\nje\\x9cli\\r\\njezeli\\r\\njeżeli\\r\\njuz\\r\\njuż\\r\\nkazdy\\r\\nkażdy\\r\\nkiedy\\r\\nkilka\\r\\nkims\\r\\nkim\\x9c\\r\\nkto\\r\\nktokolwiek\\r\\nktora\\r\\nktore\\r\\nktorego\\r\\nktorej\\r\\nktory\\r\\nktorych\\r\\nktorym\\r\\nktorzy\\r\\nktos\\r\\nkto\\x9c\\r\\nktóra\\r\\nktóre\\r\\nktórego\\r\\nktórej\\r\\nktóry\\r\\nktórych\\r\\nktórym\\r\\nktórzy\\r\\nku\\r\\nlat\\r\\nlecz\\r\\nlub\\r\\nma\\r\\nmajš\\r\\nmało\\r\\nmam\\r\\nmi\\r\\nmiedzy\\r\\nmiędzy\\r\\nmimo\\r\\nmna\\r\\nmnš\\r\\nmnie\\r\\nmoga\\r\\nmogš\\r\\nmoi\\r\\nmoim\\r\\nmoj\\r\\nmoja\\r\\nmoje\\r\\nmoze\\r\\nmozliwe\\r\\nmozna\\r\\nmoże\\r\\nmożliwe\\r\\nmożna\\r\\nmój\\r\\nmu\\r\\nmusi\\r\\nmy\\r\\nna\\r\\nnad\\r\\nnam\\r\\nnami\\r\\nnas\\r\\nnasi\\r\\nnasz\\r\\nnasza\\r\\nnasze\\r\\nnaszego\\r\\nnaszych\\r\\nnatomiast\\r\\nnatychmiast\\r\\nnawet\\r\\nnia\\r\\nniš\\r\\nnic\\r\\nnich\\r\\nnie\\r\\nniech\\r\\nniego\\r\\nniej\\r\\nniemu\\r\\nnigdy\\r\\nnim\\r\\nnimi\\r\\nniz\\r\\nniż\\r\\nno\\r\\no\\r\\nobok\\r\\nod\\r\\nokoło\\r\\non\\r\\nona\\r\\none\\r\\noni\\r\\nono\\r\\noraz\\r\\noto\\r\\nowszem\\r\\npan\\r\\npana\\r\\npani\\r\\npo\\r\\npod\\r\\npodczas\\r\\npomimo\\r\\nponad\\r\\nponiewaz\\r\\nponieważ\\r\\npowinien\\r\\npowinna\\r\\npowinni\\r\\npowinno\\r\\npoza\\r\\nprawie\\r\\nprzeciez\\r\\nprzecież\\r\\nprzed\\r\\nprzede\\r\\nprzedtem\\r\\nprzez\\r\\nprzy\\r\\nroku\\r\\nrowniez\\r\\nrównież\\r\\nsam\\r\\nsama\\r\\nsš\\r\\nsie\\r\\nsię\\r\\nskad\\r\\nskšd\\r\\nsoba\\r\\nsobš\\r\\nsobie\\r\\nsposob\\r\\nsposób\\r\\nswoje\\r\\nta\\r\\ntak\\r\\ntaka\\r\\ntaki\\r\\ntakie\\r\\ntakze\\r\\ntakże\\r\\ntam\\r\\nte\\r\\ntego\\r\\ntej\\r\\nten\\r\\nteraz\\r\\nteż\\r\\nto\\r\\ntoba\\r\\ntobš\\r\\ntobie\\r\\ntotez\\r\\ntoteż\\r\\ntotobš\\r\\ntrzeba\\r\\ntu\\r\\ntutaj\\r\\ntwoi\\r\\ntwoim\\r\\ntwoj\\r\\ntwoja\\r\\ntwoje\\r\\ntwój\\r\\ntwym\\r\\nty\\r\\ntych\\r\\ntylko\\r\\ntym\\r\\nu\\r\\nw\\r\\nwam\\r\\nwami\\r\\nwas\\r\\nwasz\\r\\nwasza\\r\\nwasze\\r\\nwe\\r\\nwedług\\r\\nwiele\\r\\nwielu\\r\\nwięc\\r\\nwięcej\\r\\nwlasnie\\r\\nwła\\x9cnie\\r\\nwszyscy\\r\\nwszystkich\\r\\nwszystkie\\r\\nwszystkim\\r\\nwszystko\\r\\nwtedy\\r\\nwy\\r\\nz\\r\\nza\\r\\nzaden\\r\\nzadna\\r\\nzadne\\r\\nzadnych\\r\\nzapewne\\r\\nzawsze\\r\\nze\\r\\nzeby\\r\\nzeznowu\\r\\nzł\\r\\nznow\\r\\nznowu\\r\\nznów\\r\\nzostal\\r\\nzostał\\r\\nżaden\\r\\nżadna\\r\\nżadne\\r\\nżadnych\\r\\nże\\r\\nżeby'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import codecs\n",
    "fileObj = codecs.open( \"stopwords_polish.txt\", \"r\", \"latin2\" )\n",
    "u = fileObj.read()\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T14:38:27.436190Z",
     "start_time": "2019-07-02T14:38:27.429340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a aby ach acz aczkolwiek aj albo ale alez ależ ani az aż bardziej bardzo beda bedzie bez deda będš bede będę będzie bo bowiem by byc być byl byla byli bylo byly był była było były bynajmniej cala cali caly cała cały ci cie ciebie cię co cokolwiek cos co\\x9c czasami czasem czemu czy czyli daleko dla dlaczego dlatego do dobrze dokad dokšd dosc do\\x9cć duzo dużo dwa dwaj dwie dwoje dzis dzisiaj dzi\\x9c gdy gdyby gdyz gdyż gdzie gdziekolwiek gdzies gdzie\\x9c go i ich ile im inna inne inny innych iz iż ja jak jakas jaka\\x9c jakby jaki jakichs jakich\\x9c jakie jakis jaki\\x9c jakiz jakiż jakkolwiek jako jakos jako\\x9c jš je jeden jedna jednak jednakze jednakże jedno jego jej jemu jesli jest jestem jeszcze je\\x9cli jezeli jeżeli juz już kazdy każdy kiedy kilka kims kim\\x9c kto ktokolwiek ktora ktore ktorego ktorej ktory ktorych ktorym ktorzy ktos kto\\x9c która które którego której który których którym którzy ku lat lecz lub ma majš mało mam mi miedzy między mimo mna mnš mnie moga mogš moi moim moj moja moje moze mozliwe mozna może możliwe można mój mu musi my na nad nam nami nas nasi nasz nasza nasze naszego naszych natomiast natychmiast nawet nia niš nic nich nie niech niego niej niemu nigdy nim nimi niz niż no o obok od około on ona one oni ono oraz oto owszem pan pana pani po pod podczas pomimo ponad poniewaz ponieważ powinien powinna powinni powinno poza prawie przeciez przecież przed przede przedtem przez przy roku rowniez również sam sama sš sie się skad skšd soba sobš sobie sposob sposób swoje ta tak taka taki takie takze także tam te tego tej ten teraz też to toba tobš tobie totez toteż totobš trzeba tu tutaj twoi twoim twoj twoja twoje twój twym ty tych tylko tym u w wam wami was wasz wasza wasze we według wiele wielu więc więcej wlasnie wła\\x9cnie wszyscy wszystkich wszystkie wszystkim wszystko wtedy wy z za zaden zadna zadne zadnych zapewne zawsze ze zeby zeznowu zł znow znowu znów zostal został żaden żadna żadne żadnych że żeby'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = u.replace('\\r\\n', ' ') # Better\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T14:38:15.344910Z",
     "start_time": "2019-07-02T14:38:15.339056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a aby ach acz aczkolwiek aj albo ale alez ależ ani az aż bardziej bardzo beda bedzie bez deda będš bede będę będzie bo bowiem by byc być byl byla byli bylo byly był była było były bynajmniej cala cali caly cała cały ci cie ciebie cię co cokolwiek cos coś czasami czasem czemu czy czyli daleko dla dlaczego dlatego do dobrze dokad dokšd dosc dość duzo dużo dwa dwaj dwie dwoje dzis dzisiaj dziś gdy gdyby gdyz gdyż gdzie gdziekolwiek gdzies gdzieś go i ich ile im inna inne inny innych iz iż ja jak jakas jakaś jakby jaki jakichs jakichś jakie jakis jakiś jakiz jakiż jakkolwiek jako jakos jakoś jš je jeden jedna jednak jednakze jednakże jedno jego jej jemu jesli jest jestem jeszcze jeśli jezeli jeżeli juz już kazdy każdy kiedy kilka kims kimś kto ktokolwiek ktora ktore ktorego ktorej ktory ktorych ktorym ktorzy ktos ktoś która które którego której który których którym którzy ku lat lecz lub ma majš mało mam mi miedzy między mimo mna mnš mnie moga mogš moi moim moj moja moje moze mozliwe mozna może możliwe można mój mu musi my na nad nam nami nas nasi nasz nasza nasze naszego naszych natomiast natychmiast nawet nia niš nic nich nie niech niego niej niemu nigdy nim nimi niz niż no o obok od około on ona one oni ono oraz oto owszem pan pana pani po pod podczas pomimo ponad poniewaz ponieważ powinien powinna powinni powinno poza prawie przeciez przecież przed przede przedtem przez przy roku rowniez również sam sama sš sie się skad skšd soba sobš sobie sposob sposób swoje ta tak taka taki takie takze także tam te tego tej ten teraz też to toba tobš tobie totez toteż totobš trzeba tu tutaj twoi twoim twoj twoja twoje twój twym ty tych tylko tym u w wam wami was wasz wasza wasze we według wiele wielu więc więcej wlasnie właśnie wszyscy wszystkich wszystkie wszystkim wszystko wtedy wy z za zaden zadna zadne zadnych zapewne zawsze ze zeby zeznowu zł znow znowu znów zostal został żaden żadna żadne żadnych że żeby'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.replace('\\x9c', 'ś')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T14:05:56.333976Z",
     "start_time": "2019-07-02T14:05:56.326164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"αλλα\\nαν\\nαντι\\nαπο\\nαυτα\\nαυτεσ\\nαυτη\\nαυτο\\nαυτοι\\nαυτοσ\\nαυτουσ\\nαυτων\\nαἱ\\nαἳ\\nαἵ\\nαὐτόσ\\nαὐτὸς\\nαὖ\\nγάρ\\nγα\\nγα^\\nγε\\nγια\\nγοῦν\\nγὰρ\\nδ'\\nδέ\\nδή\\nδαί\\nδαίσ\\nδαὶ\\nδαὶς\\nδε\\nδεν\\nδι'\\nδιά\\nδιὰ\\nδὲ\\nδὴ\\nδ’\\nεαν\\nειμαι\\nειμαστε\\nειναι\\nεισαι\\nειστε\\nεκεινα\\nεκεινεσ\\nεκεινη\\nεκεινο\\nεκεινοι\\nεκεινοσ\\nεκεινουσ\\nεκεινων\\nενω\\nεπ\\nεπι\\nεἰ\\nεἰμί\\nεἰμὶ\\nεἰς\\nεἰσ\\nεἴ\\nεἴμι\\nεἴτε\\nη\\nθα\\nισωσ\\nκ\\nκαί\\nκαίτοι\\nκαθ\\nκαι\\nκατ\\nκατά\\nκατα\\nκατὰ\\nκαὶ\\nκι\\nκἀν\\nκἂν\\nμέν\\nμή\\nμήτε\\nμα\\nμε\\nμεθ\\nμετ\\nμετά\\nμετα\\nμετὰ\\nμη\\nμην\\nμἐν\\nμὲν\\nμὴ\\nμὴν\\nνα\\nο\\nοι\\nομωσ\\nοπωσ\\nοσο\\nοτι\\nοἱ\\nοἳ\\nοἷς\\nοὐ\\nοὐδ\\nοὐδέ\\nοὐδείσ\\nοὐδεὶς\\nοὐδὲ\\nοὐδὲν\\nοὐκ\\nοὐχ\\nοὐχὶ\\nοὓς\\nοὔτε\\nοὕτω\\nοὕτως\\nοὕτωσ\\nοὖν\\nοὗ\\nοὗτος\\nοὗτοσ\\nπαρ\\nπαρά\\nπαρα\\nπαρὰ\\nπερί\\nπερὶ\\nποια\\nποιεσ\\nποιο\\nποιοι\\nποιοσ\\nποιουσ\\nποιων\\nποτε\\nπου\\nποῦ\\nπρο\\nπροσ\\nπρόσ\\nπρὸ\\nπρὸς\\nπως\\nπωσ\\nσε\\nστη\\nστην\\nστο\\nστον\\nσόσ\\nσύ\\nσύν\\nσὸς\\nσὺ\\nσὺν\\nτά\\nτήν\\nτί\\nτίς\\nτίσ\\nτα\\nταῖς\\nτε\\nτην\\nτησ\\nτι\\nτινα\\nτις\\nτισ\\nτο\\nτοί\\nτοι\\nτοιοῦτος\\nτοιοῦτοσ\\nτον\\nτοτε\\nτου\\nτούσ\\nτοὺς\\nτοῖς\\nτοῦ\\nτων\\nτό\\nτόν\\nτότε\\nτὰ\\nτὰς\\nτὴν\\nτὸ\\nτὸν\\nτῆς\\nτῆσ\\nτῇ\\nτῶν\\nτῷ\\nωσ\\nἀλλ'\\nἀλλά\\nἀλλὰ\\nἀλλ’\\nἀπ\\nἀπό\\nἀπὸ\\nἀφ\\nἂν\\nἃ\\nἄλλος\\nἄλλοσ\\nἄν\\nἄρα\\nἅμα\\nἐάν\\nἐγώ\\nἐγὼ\\nἐκ\\nἐμόσ\\nἐμὸς\\nἐν\\nἐξ\\nἐπί\\nἐπεὶ\\nἐπὶ\\nἐστι\\nἐφ\\nἐὰν\\nἑαυτοῦ\\nἔτι\\nἡ\\nἢ\\nἣ\\nἤ\\nἥ\\nἧς\\nἵνα\\nὁ\\nὃ\\nὃν\\nὃς\\nὅ\\nὅδε\\nὅθεν\\nὅπερ\\nὅς\\nὅσ\\nὅστις\\nὅστισ\\nὅτε\\nὅτι\\nὑμόσ\\nὑπ\\nὑπέρ\\nὑπό\\nὑπὲρ\\nὑπὸ\\nὡς\\nὡσ\\nὥς\\nὥστε\\nὦ\\nᾧ\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.raw('greek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"αλλα αν αντι απο αυτα αυτεσ αυτη αυτο αυτοι αυτοσ αυτουσ αυτων αἱ αἳ αἵ αὐτόσ αὐτὸς αὖ γάρ γα γα^ γε για γοῦν γὰρ δ' δέ δή δαί δαίσ δαὶ δαὶς δε δεν δι' διά διὰ δὲ δὴ δ’ εαν ειμαι ειμαστε ειναι εισαι ειστε εκεινα εκεινεσ εκεινη εκεινο εκεινοι εκεινοσ εκεινουσ εκεινων ενω επ επι εἰ εἰμί εἰμὶ εἰς εἰσ εἴ εἴμι εἴτε η θα ισωσ κ καί καίτοι καθ και κατ κατά κατα κατὰ καὶ κι κἀν κἂν μέν μή μήτε μα με μεθ μετ μετά μετα μετὰ μη μην μἐν μὲν μὴ μὴν να ο οι ομωσ οπωσ οσο οτι οἱ οἳ οἷς οὐ οὐδ οὐδέ οὐδείσ οὐδεὶς οὐδὲ οὐδὲν οὐκ οὐχ οὐχὶ οὓς οὔτε οὕτω οὕτως οὕτωσ οὖν οὗ οὗτος οὗτοσ παρ παρά παρα παρὰ περί περὶ ποια ποιεσ ποιο ποιοι ποιοσ ποιουσ ποιων ποτε που ποῦ προ προσ πρόσ πρὸ πρὸς πως πωσ σε στη στην στο στον σόσ σύ σύν σὸς σὺ σὺν τά τήν τί τίς τίσ τα ταῖς τε την τησ τι τινα τις τισ το τοί τοι τοιοῦτος τοιοῦτοσ τον τοτε του τούσ τοὺς τοῖς τοῦ των τό τόν τότε τὰ τὰς τὴν τὸ τὸν τῆς τῆσ τῇ τῶν τῷ ωσ ἀλλ' ἀλλά ἀλλὰ ἀλλ’ ἀπ ἀπό ἀπὸ ἀφ ἂν ἃ ἄλλος ἄλλοσ ἄν ἄρα ἅμα ἐάν ἐγώ ἐγὼ ἐκ ἐμόσ ἐμὸς ἐν ἐξ ἐπί ἐπεὶ ἐπὶ ἐστι ἐφ ἐὰν ἑαυτοῦ ἔτι ἡ ἢ ἣ ἤ ἥ ἧς ἵνα ὁ ὃ ὃν ὃς ὅ ὅδε ὅθεν ὅπερ ὅς ὅσ ὅστις ὅστισ ὅτε ὅτι ὑμόσ ὑπ ὑπέρ ὑπό ὑπὲρ ὑπὸ ὡς ὡσ ὥς ὥστε ὦ ᾧ \""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.raw('greek').replace('\\n', ' ') # Better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `.sents()` which returns sentences. However, in our particular case, this will cause an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WordListCorpusReader' object has no attribute 'sents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e1185800ddd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'greek'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'WordListCorpusReader' object has no attribute 'sents'"
     ]
    }
   ],
   "source": [
    "stopwords.sents('greek')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The erro is because the `stopwords` corpus reader is of type `WordListCorpusReader` so there are no sentences.\n",
    "It's the same for `.paras()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "444"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words(['english', 'greek'])) # There is a total of 444 Greek and English stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We loop through the list of stop words in all languages and check how many stop words our test text contains in each language. The text is then classified to be in the language in which it has the most stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arabic': 0,\n",
       " 'azerbaijani': 0,\n",
       " 'danish': 3,\n",
       " 'dutch': 0,\n",
       " 'english': 8,\n",
       " 'finnish': 0,\n",
       " 'french': 2,\n",
       " 'german': 1,\n",
       " 'greek': 0,\n",
       " 'hungarian': 1,\n",
       " 'italian': 1,\n",
       " 'kazakh': 0,\n",
       " 'nepali': 0,\n",
       " 'norwegian': 3,\n",
       " 'portuguese': 1,\n",
       " 'romanian': 2,\n",
       " 'russian': 0,\n",
       " 'spanish': 1,\n",
       " 'swedish': 2,\n",
       " 'turkish': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_ratios = {}\n",
    "\n",
    "test_words = [word.lower() for word in test_tokens] # lowercase all tokens\n",
    "test_words_set = set(test_words)\n",
    "\n",
    "for language in stopwords.fileids():\n",
    "    stopwords_set = set(stopwords.words(language)) # For some languages eg. Russian, it would be a wise idea to tokenize the stop words by punctuation too.\n",
    "    common_elements = test_words_set.intersection(stopwords_set)\n",
    "    language_ratios[language] = len(common_elements) # language \"score\"\n",
    "    \n",
    "language_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'english'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_rated_language = max(language_ratios, key=language_ratios.get) # The key parameter to the max() function is a function that computes a key. In our case, we already have a key so we set key to languages_ratios.get which actually returns the key.\n",
    "most_rated_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ain', 'for', 'i', 'it', 's', 't', 'to', 'you'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_words_set.intersection(set(stopwords.words(most_rated_language))) # We can see which English stop words were found."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
